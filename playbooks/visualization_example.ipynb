{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42921317",
   "metadata": {},
   "source": "### Set up model and define necessary stuff"
  },
  {
   "cell_type": "code",
   "id": "0d9d67d5",
   "metadata": {},
   "source": [
    "import os\n",
    "from typing import Type\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.centernet import ModelBuilder\n",
    "from data.dataset_visualizer import ImageDatasetWithLabels\n",
    "from torch.utils.data import Subset\n",
    "from postprocess_visual.object_detection_visualizer import (\n",
    "    ObjectDetectionVisualizer,\n",
    ")\n",
    "\n",
    "\n",
    "Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_model(model_type: Type[nn.Module], checkpoint_path: str = None):\n",
    "    checkpoint_path = (\n",
    "        \"../models/checkpoints/pretrained_weights.pt\"\n",
    "        if checkpoint_path is None\n",
    "        else checkpoint_path\n",
    "    )\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "    model = model_type(alpha=0.25).to(Device)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            checkpoint_path,\n",
    "            map_location=Device,\n",
    "            weights_only=True,\n",
    "        )\n",
    "    )\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def transform_dataset(dataset):\n",
    "    \"\"\"Transform the dataset for visualization\"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(256, 256)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return ImageDatasetWithLabels(dataset=dataset, transformation=transform)\n",
    "\n",
    "\n",
    "def get_predictions(model, dataset):\n",
    "    \"\"\"Get model predictions for the given dataset\"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToImage(),\n",
    "            transforms.ToDtype(torch.float32, scale=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    for _, orig_img in enumerate(dataset):\n",
    "        # Apply transformations\n",
    "        img = transform(orig_img)\n",
    "        img = img.unsqueeze(0).to(Device)\n",
    "\n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            pred = model(img)\n",
    "\n",
    "        predictions.append(pred)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "model = load_model(ModelBuilder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get predictions for defined dataset",
   "id": "68bfeb2f53db37a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_dataset():\n",
    "    # Load VOC dataset\n",
    "    dataset_val = torchvision.datasets.VOCDetection(\n",
    "        root=\"../VOC\", year=\"2007\", image_set=\"val\", download=False\n",
    "    )\n",
    "    dataset_val = torchvision.datasets.wrap_dataset_for_transforms_v2(dataset_val)\n",
    "\n",
    "    # Define a dataset that is a subset of the initial dataset\n",
    "    indices = range(10)\n",
    "    dataset_val = Subset(dataset_val, indices)\n",
    "\n",
    "    return dataset_val\n",
    "\n",
    "dataset = prepare_dataset()\n",
    "\n",
    "# Transform the dataset to the correct form for further processing\n",
    "dataset_transformed = transform_dataset(dataset)\n",
    "\n",
    "# Get predictions\n",
    "predictions = get_predictions(model, dataset_transformed)"
   ],
   "id": "7ecc6696a43d9415",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91a9586f",
   "metadata": {},
   "source": "### Predictions visualization"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create visualizer with default settings\n",
    "visualizer = ObjectDetectionVisualizer(\n",
    "    dataset=dataset_transformed, input_height=256, input_width=256, confidence_threshold=0.3\n",
    ")\n",
    "\n",
    "# Visualize predictions\n",
    "visualizer.visualize_predictions(predictions)"
   ],
   "id": "b64c81a7d8d163eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "42ea5ad103d5227a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from sympy import false\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import custom modules\n",
    "from training.encoder import CenternetEncoder\n",
    "from postrprocess_visual.postprocess import CenternetPostprocess\n",
    "from postrprocess_visual.visualizer import get_image_with_bboxes, PASCAL_CLASSES\n",
    "from models.centernet import ModelBuilder\n",
    "\n",
    "def prepare_dataset():\n",
    "    \"\"\"Prepare the validation dataset\"\"\"\n",
    "    try:\n",
    "        # Load VOC dataset\n",
    "        dataset_val = torchvision.datasets.VOCDetection(root=\"VOC\", year='2007', image_set=\"val\", download=false)\n",
    "        dataset_val = torchvision.datasets.wrap_dataset_for_transforms_v2(dataset_val)\n",
    "\n",
    "        # Select first 30 indices for visualization\n",
    "        indices = list(range(min(30, len(dataset_val))))\n",
    "        dataset_val = Subset(dataset_val, indices)\n",
    "\n",
    "        return dataset_val\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error preparing dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_transforms(input_height=256, input_width=256):\n",
    "    \"\"\"Create image transforms\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size=(input_width, input_height)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "def load_trained_model(checkpoint_path, device):\n",
    "    \"\"\"Load the trained CenterNet model\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "        model = ModelBuilder(alpha=0.25).to(device)\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device, weights_only=True))\n",
    "        model.eval()\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {e}\")\n",
    "        raise\n",
    "\n",
    "def visualize_predictions(model, dataset, transform, encoder, postprocessor, device, num_samples=5, confidence_threshold=0.3):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    plt.figure(figsize=(15, 3*num_samples))\n",
    "\n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        # Get original image and ground truth\n",
    "        orig_img, orig_label = dataset[i]\n",
    "\n",
    "        # Apply transforms\n",
    "        img, bboxes, labels = transform(orig_img, orig_label['boxes'], orig_label['labels'])\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "\n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            pred = model(img)\n",
    "\n",
    "        # Postprocess predictions\n",
    "        detections = postprocessor(pred)\n",
    "\n",
    "        # Convert to numpy for processing\n",
    "        img_np = np.transpose(img.cpu().squeeze().numpy(), (1, 2, 0))\n",
    "        img_np = (img_np * 0.5) + 0.5  # Denormalize\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "        # Reconstruct bounding boxes\n",
    "        img_h, img_w = img_np.shape[:2]\n",
    "        pred_boxes = []\n",
    "        pred_labels = []\n",
    "\n",
    "        for det in detections[0]:\n",
    "            class_id = int(det[0].item())\n",
    "            score = det[1].item()\n",
    "\n",
    "            # Only process detections with reasonable confidence\n",
    "            if score > confidence_threshold:\n",
    "                x1 = int(det[2].item() * img_w)\n",
    "                y1 = int(det[3].item() * img_h)\n",
    "                x2 = int(det[4].item() * img_w)\n",
    "                y2 = int(det[5].item() * img_h)\n",
    "\n",
    "                pred_boxes.append([x1, y1, x2, y2])\n",
    "                pred_labels.append(class_id)\n",
    "\n",
    "        # Visualize\n",
    "        plt.subplot(num_samples, 2, 2*i+1)\n",
    "        plt.title(f'Original Image {i+1}')\n",
    "        plt.imshow(orig_img)\n",
    "\n",
    "        plt.subplot(num_samples, 2, 2*i+2)\n",
    "        plt.title(f'Predictions {i+1}')\n",
    "        img_with_pred = img_np.copy()\n",
    "\n",
    "        # Draw predicted bounding boxes\n",
    "        for box, label in zip(pred_boxes, pred_labels):\n",
    "            cv2.rectangle(img_with_pred,\n",
    "                          (box[0], box[1]),\n",
    "                          (box[2], box[3]),\n",
    "                          (0, 255, 0), 2)\n",
    "            # Add class label\n",
    "            cv2.putText(img_with_pred,\n",
    "                        PASCAL_CLASSES[label-1],\n",
    "                        (box[0], box[1]-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5, (0, 255, 0), 2)\n",
    "\n",
    "        plt.imshow(img_with_pred)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Device configuration\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f\"Using device: {device}\")\n",
    "\n",
    "        # Hyperparameters\n",
    "        input_height = input_width = 256\n",
    "        down_ratio = 4\n",
    "        checkpoint_path = 'models/checkpoints/pascal_voc_final_weights.pt'\n",
    "\n",
    "        # Prepare components\n",
    "        dataset = prepare_dataset()\n",
    "        transform = create_transforms(input_height, input_width)\n",
    "        encoder = CenternetEncoder(input_height, input_width)\n",
    "        postprocessor = CenternetPostprocess(n_classes=20, width=input_width, height=input_height, down_ratio=down_ratio).to(device)\n",
    "\n",
    "        # Load trained model\n",
    "        model = load_trained_model(checkpoint_path, device)\n",
    "\n",
    "        # Visualize predictions\n",
    "        visualize_predictions(model, dataset, transform, encoder, postprocessor, device)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
